# -*- coding: utf-8 -*-
"""Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Uks8RQeqzOafNZXAS8AHtSsfve_8dNEO
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import pathlib
from tensorflow import keras
from tensorflow.keras.layers.experimental import preprocessing
from tensorflow.keras import layers
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Conv1D, Activation, BatchNormalization,Dropout, MaxPooling1D,Flatten,Dense
from keras.utils import to_categorical
from tensorflow.keras import models
from IPython import display
import os
from sklearn.utils import shuffle
from os.path import isdir, join
from pathlib import Path
from scipy.fftpack import fft
from scipy import signal
from scipy.io import wavfile
import librosa
import matplotlib.pyplot as plt
import IPython.display as ipd
import librosa.display
import plotly.offline as py
py.init_notebook_mode(connected=True)
import plotly.graph_objs as go
import plotly.tools as tls
# %matplotlib inline
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn import svm
import tensorflow as tf

# Set seed for experiment reproducibility
seed = 16
tf.random.set_seed(seed)
np.random.seed(seed)

#data generation
tf.keras.utils.get_file(
    'mini_speech_commands.zip',
     origin="http://storage.googleapis.com/download.tensorflow.org/data/mini_speech_commands.zip",
     extract=True,
     cache_dir='.', cache_subdir='data')
data_dir = pathlib.Path('/content/data/mini_speech_commands')

commands = np.array(tf.io.gfile.listdir(str(data_dir)))
commands = commands[commands != 'README.md']
print('Commands:', commands)

filenames = tf.io.gfile.glob(str(data_dir) + '/*/*')
filenames = tf.random.shuffle(filenames)
num_samples = len(filenames)
print(num_samples)

filenames[0]

check = filenames[0].numpy()
check

check.decode("utf-8")

sample_rate , samples = wavfile.read(check)

samples.shape

freq, time, spectrogram = signal.spectrogram(samples , fs = sample_rate)

# fig = plt.figure(figsize=(14, 8))


# ax1 = fig.add_subplot(211)

# ax1.set_ylabel('Amplitude')
# ax1.plot(np.linspace(0, sample_rate/len(samples), sample_rate), samples)



# ax2 = fig.add_subplot(212)
# ax2.imshow(spectrogram.T, aspect='auto', origin='lower', 
#            extent=[time.min(), time.max(), freq.min(), freq.max()])
# ax2.set_yticks(freq[::16])
# ax2.set_xticks(time[::16])

# ax2.set_ylabel('Freqs in Hz')
# ax2.set_xlabel('Seconds')

# # plt.show()

samples, sample_rate = librosa.load(check)

spect = librosa.feature.melspectrogram(samples, sr=sample_rate, n_mels=128)
log_spect = librosa.power_to_db(spect, ref=np.max)

plt.figure(figsize=(12, 4))
librosa.display.specshow(log_spect, sr=sample_rate, x_axis='time', y_axis='mel')
plt.title('Mel power spectrogram ')
plt.colorbar(format='%+02.0f dB')
plt.tight_layout()

filename = []

for f in filenames:
  filename.append(f.numpy().decode("utf-8"))
# filename

sample_rates=[]
samples = []
label = []
for f in filename:
  smpl,smpl_rt = librosa.load(f)
  smpl = librosa.resample(smpl,smpl_rt,8000)
  samples.append(smpl)
  sample_rates.append(8000)
  label.append(f.rsplit("/",2)[1])
# samples
df = pd.DataFrame()
df['Sample'] = samples
df['Sample_Rate'] = sample_rates
df["Label"] = label
df

df.describe()

df.info()

df.isnull().sum()

df.isnull().sum()

count = df["Label"].value_counts()
count

sns.histplot(data = df , x = 'Label' )
plt.show()

def plot_spect(sample_rate , samples , label , val):
  fig = plt.figure(figsize=(14, 8))
  ax = fig.add_subplot(8 , 1 , val )
  ax.set_ylabel('Amplitude')
  plt.title(label)
  ax.plot(np.linspace(0, sample_rate/len(samples), sample_rate), samples)

'''
val = 1

for i in range(df.shape[0]):
  plot_spect(df['Sample_Rate'][i] , df['Sample'][i] , df['Label'][i], val )
  val = val + 1
'''

encode_label = {'Label' : {'go' : 0 , 'up' : 1 , 'stop' : 2 , 'no' : 3 , 'down' : 4 ,
                           'yes' : 5 , 'right' : 6 , 'left' :7}}

dfr = df.replace(encode_label)
dfr.head(n=10)

dfr.shape

#dfr = dataframe
array = dfr.pop('Sample')
df_re = pd.concat([array.apply(pd.Series), dfr['Sample_Rate'] , dfr['Label']], axis=1)

array.apply(pd.Series).shape

df_re.head()

dropped = df_re.dropna(axis=0)

dropped.shape

val_count = df_re['Label'].value_counts()
val_count

val_count = dropped["Label"].value_counts()
val_count

'''
col = [i for i in range(16000)]
str_col = [str(col[i]) for i in range(16000) ]
str_col[0:4]
'''

'''
f = pd.DataFrame()
for i in range(8000):
  for j in range(len(features["Sample"][i])):
    f[str_col[j]] = features['Sample'][i][j]
'''

"""Dataset split"""

#df_re
dropped.head(5)

X = dropped.iloc[:,0:8000].values
Y = pd.DataFrame(dropped['Label'],columns=['Label'])

len(Y)

X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2,random_state=42)

clf = DecisionTreeClassifier( criterion='gini' , max_depth=100)
clf.fit(X_train,Y_train)
clf.score(X_test , Y_test)*100

clf2 = svm.SVC(kernel='rbf' , random_state=16 )
clf2.fit(X_train,Y_train.ravel())
clf2.score(X_test , Y_test)*100

X_train = X_train.reshape(-1,8000,1)
X_test = X_test.reshape(-1,8000,1)

# New modelT
model = Sequential()
model.add(Conv1D(256, 8, padding='same',input_shape=(X_train.shape[1],1)))  # X_train.shape[1] = No. of Columns
model.add(Activation('relu'))
model.add(Conv1D(256, 8, padding='same'))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(Dropout(0.25))
model.add(MaxPooling1D(pool_size=(8)))
model.add(Conv1D(128, 8, padding='same'))
model.add(Activation('relu'))
model.add(Conv1D(128, 8, padding='same'))
model.add(Activation('relu'))
model.add(Conv1D(128, 8, padding='same'))
model.add(Activation('relu'))
model.add(Conv1D(128, 8, padding='same'))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(Dropout(0.25))
model.add(MaxPooling1D(pool_size=(8)))
model.add(Conv1D(64, 8, padding='same'))
model.add(Activation('relu'))
model.add(Conv1D(64, 8, padding='same'))
model.add(Activation('relu'))
model.add(Flatten())
model.add(Dense(8)) # Target class number
model.add(Activation('softmax'))
# opt = keras.optimizers.SGD(lr=0.0001, momentum=0.0, decay=0.0, nesterov=False)
# opt = keras.optimizers.Adam(lr=0.0001)
opt = keras.optimizers.RMSprop(lr=0.00001, decay=1e-6)
model.summary()

y_train = to_categorical(Y_train, dtype ="uint8")
y_test = to_categorical(Y_test, dtype ="uint8")

model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])
model_history=model.fit(X_train, y_train, batch_size=64, epochs=100, validation_data=(X_test, y_test),verbose = 1)